{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoderモデルの定義など"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "input_img = Input(shape=(604,604,3))  # adapt this if using `channels_first` image data format\n",
    "# input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "def ae_model(img):\n",
    "    print(img)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(img)\n",
    "    print(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    print(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    print(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    print(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    print(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same', name='encoded')(x)\n",
    "\n",
    "    # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    print(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    print(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    print(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    print(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "    print(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    print(x)\n",
    "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    print(decoded)\n",
    "    return encoded, decoded\n",
    "\n",
    "encoded, decoded = ae_model(input_img)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像入力のヘルパ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    from PIL import Image\n",
    "    image = Image.open(path)\n",
    "    return image\n",
    "\n",
    "def reshape(image):\n",
    "    \"\"\"\n",
    "    Making gotten images regular size.\n",
    "    Arg:\n",
    "        image: 3-D Tensor\n",
    "\n",
    "    Return:\n",
    "        reshaped: reshaped images\n",
    "    \"\"\"\n",
    "\n",
    "    max_size = tf.reduce_max(tf.shape(image))\n",
    "    new_height = 604\n",
    "    new_width = 604\n",
    "\n",
    "    reshaped = tf.image.resize_images(tf.image.resize_image_with_crop_or_pad(image, max_size, max_size),[new_height, new_width])\n",
    "    return reshaped.numpy()\n",
    "\n",
    "def size_decision(image):\n",
    "    \"\"\"\n",
    "    Helper function.\n",
    "    Returning longer edge size.\n",
    "\n",
    "    Arg:\n",
    "        image: 3-D Tensor\n",
    "    Return:\n",
    "        size: longer edge size\n",
    "    \"\"\"\n",
    "    return tf.reduce_max(tf.shape(image))\n",
    "\n",
    "\n",
    "def helper():\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from keras.preprocessing.image import  img_to_array, array_to_img\n",
    "    train = os.listdir('train')\n",
    "    valid = os.listdir('valid')\n",
    "    \n",
    "    t_img_path = ['train/'+x for x in train if x != '.DS_Store']\n",
    "    v_img_path = ['valid/'+x for x in valid if x != '.DS_Store']\n",
    "    \n",
    "    t_img = []\n",
    "    for x in t_img_path:\n",
    "        x = load_img(x)\n",
    "        x = img_to_array(x)\n",
    "        if x.shape == (604,604,3):\n",
    "            t_img.append(x)\n",
    "    t_img = np.asarray(t_img)\n",
    "    print(t_img.shape)\n",
    "        \n",
    "    v_img = []\n",
    "    for x in v_img_path:\n",
    "        x = load_img(x)\n",
    "        x = img_to_array(x)\n",
    "        v_img.append(x)\n",
    "    print(type(v_img))\n",
    "    \n",
    "    return np.asarray(t_img), np.asarray(v_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像などの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import  img_to_array, array_to_img\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# (x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = helper()\n",
    "setX = [x.shape for x in x_train]\n",
    "print(setX)\n",
    "print(type(x_train))\n",
    "\n",
    "x_train = x_train.astype(np.float32) / 255.\n",
    "x_test = x_test.astype(np.float32) / 255.\n",
    "# x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "# x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), 604, 604, 3))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 604, 604, 3))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=12,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validationしてみたり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "# image = array_to_img(decoded_imgs[0].reshape(604, 604, 3))\n",
    "# plt.imshow(np.asarray(image))\n",
    "# plt.show()\n",
    "\n",
    "n = len(decoded_imgs)\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(604, 604, 3))\n",
    "    plt.colors()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n +1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(604, 604, 3))\n",
    "    plt.colors()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中間層取り出しと類似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "layer_name = 'encoded'\n",
    "intermediate_layer_model = Model(inputs=autoencoder.input,\n",
    "                                 outputs=autoencoder.get_layer(layer_name).output)\n",
    "\n",
    "encoded_train = intermediate_layer_model.predict(x_train)\n",
    "encoded_valid = intermediate_layer_model.predict(x_test)\n",
    "\n",
    "def get_nearest_value(nplist, num):\n",
    "    idx = np.abs(nplist - num).argmin()\n",
    "    return idx\n",
    "\n",
    "def euclid(y,x):\n",
    "    '''\n",
    "    Euclid distance\n",
    "    '''\n",
    "    return np.linalg.norm(y-x)\n",
    "\n",
    "def cosie(y,x):\n",
    "    '''\n",
    "    cosine simmiler(?)\n",
    "    '''\n",
    "    import scipy.spatial.distance as dis\n",
    "    \n",
    "    return dis.cosine(y.flatten(), x.flatten())\n",
    "\n",
    "print 'encoded_train'\n",
    "# counter = 0\n",
    "# for x in encoded_valid:\n",
    "#     diff = [np.linalg.norm(y-x) for y in encoded_train]\n",
    "#     t_image = x_train[int(np.asarray(diff).argmin())]\n",
    "#     v_image = x_test[counter]\n",
    "#     load_img(array_to_img(t_image.reshape(604, 604, 3)))\n",
    "#     load_img(array_to_img(v_image.reshape(604, 604, 3)))\n",
    "    \n",
    "#     counter+=1\n",
    "    \n",
    "    \n",
    "n = len(encoded_valid)\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i in range(n):\n",
    "    diff = [cosie(y, encoded_valid[i]) for y in encoded_train]\n",
    "    t_image = x_train[int(np.asarray(diff).argmin())]\n",
    "    v_image = x_test[i]\n",
    "    \n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(v_image.reshape(604, 604, 3))\n",
    "    plt.colors()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n+1)\n",
    "    plt.imshow(t_image.reshape(604, 604, 3))\n",
    "    print(i+1, i+n+1)\n",
    "    plt.colors()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ラムダ式使うとこうなるっぽい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "c = 3\n",
    "def add():\n",
    "    return lambda x,y: x+y*c\n",
    "\n",
    "def subtract():\n",
    "    return lambda x,y: x-y\n",
    "add()(add()(a,b),c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
